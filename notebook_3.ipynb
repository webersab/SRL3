{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from booknlp.booknlp import BookNLP\n",
    "\n",
    "model_params={\n",
    "\t\t\"pipeline\":\"entity,quote,supersense,event,coref\", \n",
    "\t\t\"model\":\"big\"\n",
    "\t}\n",
    "\t\n",
    "booknlp=BookNLP(\"en\", model_params)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- spacy: 7.329 seconds ---\n",
      "--- entities: 42.074 seconds ---\n",
      "--- quotes: 0.043 seconds ---\n",
      "--- attribution: 86.122 seconds ---\n",
      "--- name coref: 0.046 seconds ---\n",
      "--- coref: 49.892 seconds ---\n",
      "--- TOTAL (excl. startup): 185.642 seconds ---, 81696 words\n"
     ]
    }
   ],
   "source": [
    "# Input file to process\n",
    "input_file=\"a_little_princess.txt\"\n",
    "\n",
    "# Output directory to store resulting files in\n",
    "output_directory=\"./output_dir/princess/\"\n",
    "\n",
    "# File within this directory will be named ${book_id}.entities, ${book_id}.tokens, etc.\n",
    "book_id=\"princess\"\n",
    "\n",
    "booknlp.process(input_file, output_directory, book_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "def proc(filename):\n",
    "    with open(filename) as file:\n",
    "        data=json.load(file)\n",
    "    return data\n",
    "\n",
    "data=proc(\"./output_dir/bartleby/bartleby.book\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 522 Bartleby he/him/his\n",
      "\n",
      "\tposs\t5 desk\n",
      "\tposs\t5 hermitage\n",
      "\tposs\t5 screen\n",
      "\tposs\t4 eyes\n",
      "\tposs\t4 window\n",
      "\tposs\t3 papers\n",
      "\tposs\t3 ways\n",
      "\tposs\t2 services\n",
      "\tposs\t2 writing\n",
      "\tposs\t2 privacy\n",
      "\tposs\t2 face\n",
      "\tposs\t2 manner\n",
      "\tposs\t2 conduct\n",
      "\tposs\t2 eccentricities\n",
      "\tposs\t2 home\n",
      "\tposs\t2 history\n",
      "\tposs\t2 place\n",
      "\tposs\t1 case\n",
      "\tposs\t1 youth\n",
      "\tposs\t1 qualifications\n",
      "\tposs\t1 application\n",
      "\tposs\t1 copy\n",
      "\tposs\t1 retreat\n",
      "\tposs\t1 eye\n",
      "\tposs\t1 document\n",
      "\tposs\t1 legs\n",
      "\tposs\t1 copies\n",
      "\tposs\t1 request\n",
      "\tposs\t1 decision\n",
      "\tposs\t1 business\n",
      "\tposs\t1 evinces\n",
      "\tposs\t1 willfulness\n",
      "\tposs\t1 freedom\n",
      "\tposs\t1 industry\n",
      "\tposs\t1 stillness\n",
      "\tposs\t1 unalterableness\n",
      "\tposs\t1 honesty\n",
      "\tposs\t1 hands\n",
      "\tposs\t1 part\n",
      "\tposs\t1 finger\n",
      "\tposs\t1 _\n",
      "\tposs\t1 mildness\n",
      "\tposs\t1 clerk\n",
      "\tposs\t1 premises\n",
      "\tposs\t1 sleeves\n",
      "\tposs\t1 poverty\n",
      "\tposs\t1 solitude\n",
      "\tposs\t1 etc\n",
      "\tposs\t1 .\n",
      "\tposs\t1 glance\n",
      "\tposs\t1 answer\n",
      "\tposs\t1 countenance\n",
      "\tposs\t1 perverseness\n",
      "\tposs\t1 behavior\n",
      "\tposs\t1 reply\n",
      "\tposs\t1 tongue\n",
      "\tposs\t1 revery\n",
      "\tposs\t1 diligence\n",
      "\tposs\t1 stay\n",
      "\tposs\t1 vision\n",
      "\tposs\t1 account\n",
      "\tposs\t1 shoulder\n",
      "\tposs\t1 back\n",
      "\tposs\t1 things\n",
      "\tposs\t1 key\n",
      "\tposs\t1 traps\n",
      "\tposs\t1 chair\n",
      "\tposs\t1 taxes\n",
      "\tposs\t1 accord\n",
      "\tposs\t1 apple\n",
      "\tposs\t1 reveries\n",
      "\tposs\t1 talk\n",
      "\tposs\t1 office\n",
      "\tposs\t1 savings\n",
      "\tposs\t1 occupancy\n",
      "\tposs\t1 departure\n",
      "\tposs\t1 consideration\n",
      "\tposs\t1 determination\n",
      "\tposs\t1 health\n",
      "\tposs\t1 suspicion\n",
      "\tposs\t1 sarvant\n",
      "\tposs\t1 cell\n",
      "\tposs\t1 acquaintance\n",
      "\n",
      "\tagent\t17 prefer\n",
      "\tagent\t7 said\n",
      "\tagent\t6 replied\n",
      "\tagent\t5 do\n",
      "\tagent\t4 go\n",
      "\tagent\t3 seemed\n",
      "\tagent\t3 went\n",
      "\tagent\t3 did\n",
      "\tagent\t3 remained\n",
      "\tagent\t3 doing\n",
      "\tagent\t3 answered\n",
      "\tagent\t3 quit\n",
      "\tagent\t3 remain\n",
      "\tagent\t2 mean\n",
      "\tagent\t2 help\n",
      "\tagent\t2 eats\n",
      "\tagent\t2 preferred\n",
      "\tagent\t2 declined\n",
      "\tagent\t2 slid\n",
      "\tagent\t2 tell\n",
      "\tagent\t2 retired\n",
      "\tagent\t2 given\n",
      "\tagent\t2 leave\n",
      "\tagent\t2 removed\n",
      "\tagent\t2 like\n",
      "\tagent\t2 know\n",
      "\tagent\t1 ran\n",
      "\tagent\t1 wrote\n",
      "\tagent\t1 snatch\n",
      "\tagent\t1 proceed\n",
      "\tagent\t1 misunderstood\n",
      "\tagent\t1 concluded\n",
      "\tagent\t1 appeared\n",
      "\tagent\t1 disappeared\n",
      "\tagent\t1 refuse\n",
      "\tagent\t1 speak\n",
      "\tagent\t1 revolved\n",
      "\tagent\t1 comprehended\n",
      "\tagent\t1 gave\n",
      "\tagent\t1 lives\n",
      "\tagent\t1 means\n",
      "\tagent\t1 intends\n",
      "\tagent\t1 fall\n",
      "\tagent\t1 treated\n",
      "\tagent\t1 says\n",
      "\tagent\t1 examine\n",
      "\tagent\t1 think\n",
      "\tagent\t1 left\n",
      "\tagent\t1 chose\n",
      "\tagent\t1 permits\n",
      "\tagent\t1 order\n",
      "\tagent\t1 ate\n",
      "\tagent\t1 slept\n",
      "\tagent\t1 making\n",
      "\tagent\t1 makes\n",
      "\tagent\t1 seen\n",
      "\tagent\t1 supposed\n",
      "\tagent\t1 desired\n",
      "\tagent\t1 found\n",
      "\tagent\t1 have\n",
      "\tagent\t1 feel\n",
      "\tagent\t1 look\n",
      "\tagent\t1 kept\n",
      "\tagent\t1 received\n",
      "\tagent\t1 begin\n",
      "\tagent\t1 overheard\n",
      "\tagent\t1 give\n",
      "\tagent\t1 prefers\n",
      "\tagent\t1 opened\n",
      "\tagent\t1 stand\n",
      "\tagent\t1 write\n",
      "\tagent\t1 decided\n",
      "\tagent\t1 urged\n",
      "\tagent\t1 vouchsafed\n",
      "\tagent\t1 informed\n",
      "\tagent\t1 copy\n",
      "\tagent\t1 became\n",
      "\tagent\t1 stay\n",
      "\tagent\t1 become\n",
      "\tagent\t1 occasioned\n",
      "\tagent\t1 restored\n",
      "\tagent\t1 dropped\n",
      "\tagent\t1 take\n",
      "\tagent\t1 made\n",
      "\tagent\t1 lock\n",
      "\tagent\t1 please\n",
      "\tagent\t1 bundle\n",
      "\tagent\t1 does\n",
      "\tagent\t1 fell\n",
      "\tagent\t1 depart\n",
      "\tagent\t1 withstand\n",
      "\tagent\t1 touched\n",
      "\tagent\t1 see\n",
      "\tagent\t1 decline\n",
      "\tagent\t1 turning\n",
      "\tagent\t1 spent\n",
      "\tagent\t1 apprised\n",
      "\tagent\t1 came\n",
      "\tagent\t1 done\n",
      "\tagent\t1 want\n",
      "\n",
      "\tpatient\t2 assist\n",
      "\tpatient\t2 found\n",
      "\tpatient\t2 prefer\n",
      "\tpatient\t2 see\n",
      "\tpatient\t2 gone\n",
      "\tpatient\t1 engaged\n",
      "\tpatient\t1 assign\n",
      "\tpatient\t1 isolate\n",
      "\tpatient\t1 remove\n",
      "\tpatient\t1 gorge\n",
      "\tpatient\t1 placing\n",
      "\tpatient\t1 rippled\n",
      "\tpatient\t1 dismissed\n",
      "\tpatient\t1 said\n",
      "\tpatient\t1 thrust\n",
      "\tpatient\t1 addressing\n",
      "\tpatient\t1 known\n",
      "\tpatient\t1 turn\n",
      "\tpatient\t1 treated\n",
      "\tpatient\t1 humor\n",
      "\tpatient\t1 encounter\n",
      "\tpatient\t1 throw\n",
      "\tpatient\t1 order\n",
      "\tpatient\t1 owe\n",
      "\tpatient\t1 ask\n",
      "\tpatient\t1 tell\n",
      "\tpatient\t1 born\n",
      "\tpatient\t1 dismiss\n",
      "\tpatient\t1 entreat\n",
      "\tpatient\t1 mending\n",
      "\tpatient\t1 enabling\n",
      "\tpatient\t1 asking\n",
      "\tpatient\t1 urged\n",
      "\tpatient\t1 asked\n",
      "\tpatient\t1 told\n",
      "\tpatient\t1 warned\n",
      "\tpatient\t1 fare\n",
      "\tpatient\t1 bundle\n",
      "\tpatient\t1 vanished\n",
      "\tpatient\t1 occupied\n",
      "\tpatient\t1 killed\n",
      "\tpatient\t1 touched\n",
      "\tpatient\t1 imagined\n",
      "\tpatient\t1 grappled\n",
      "\tpatient\t1 threw\n",
      "\tpatient\t1 billeted\n",
      "\tpatient\t1 furnish\n",
      "\tpatient\t1 concerning\n",
      "\tpatient\t1 contemplating\n",
      "\tpatient\t1 request\n",
      "\tpatient\t1 motioned\n",
      "\tpatient\t1 shield\n",
      "\tpatient\t1 receive\n",
      "\tpatient\t1 permitted\n",
      "\tpatient\t1 brought\n",
      "\tpatient\t1 left\n",
      "\tpatient\t1 finding\n",
      "\tpatient\t1 removed\n",
      "\n",
      "\tmod\t3 man\n",
      "\tmod\t1 industrious\n",
      "\tmod\t1 sentry\n",
      "\tmod\t1 vegetarian\n",
      "\tmod\t1 useful\n",
      "\tmod\t1 person\n",
      "\tmod\t1 sons\n",
      "\tmod\t1 inflexible\n",
      "\tmod\t1 air\n",
      "\tmod\t1 harmless\n",
      "\tmod\t1 noiseless\n",
      "\tmod\t1 aware\n",
      "\tmod\t1 cause\n",
      "\tmod\t1 unused\n",
      "\tmod\t1 clerk\n",
      "\n",
      "32 150 Turkey he/him/his\n",
      "\n",
      "\tposs\t2 face\n",
      "\tposs\t2 countenance\n",
      "\tposs\t2 papers\n",
      "\tposs\t2 services\n",
      "\tposs\t2 coats\n",
      "\tposs\t2 coat\n",
      "\tposs\t1 hour\n",
      "\tposs\t1 beams\n",
      "\tposs\t1 capacities\n",
      "\tposs\t1 pen\n",
      "\tposs\t1 inkstand\n",
      "\tposs\t1 blots\n",
      "\tposs\t1 chair\n",
      "\tposs\t1 box\n",
      "\tposs\t1 pens\n",
      "\tposs\t1 table\n",
      "\tposs\t1 eccentricities\n",
      "\tposs\t1 tongue\n",
      "\tposs\t1 ways\n",
      "\tposs\t1 labors\n",
      "\tposs\t1 lodgings\n",
      "\tposs\t1 devotions\n",
      "\tposs\t1 columns\n",
      "\tposs\t1 clothes\n",
      "\tposs\t1 pantaloons\n",
      "\tposs\t1 hat\n",
      "\tposs\t1 civility\n",
      "\tposs\t1 deference\n",
      "\tposs\t1 money\n",
      "\tposs\t1 rashness\n",
      "\tposs\t1 obstreperousness\n",
      "\tposs\t1 oats\n",
      "\tposs\t1 paroxysms\n",
      "\tposs\t1 tone\n",
      "\tposs\t1 answer\n",
      "\tposs\t1 opinion\n",
      "\tposs\t1 steaming\n",
      "\tposs\t1 hands\n",
      "\tposs\t1 screen\n",
      "\tposs\t1 eyes\n",
      "\tposs\t1 feet\n",
      "\tposs\t1 arms\n",
      "\tposs\t1 promise\n",
      "\tposs\t1 mind\n",
      "\tposs\t1 fists\n",
      "\n",
      "\tagent\t7 think\n",
      "\tagent\t4 said\n",
      "\tagent\t3 made\n",
      "\tagent\t2 go\n",
      "\tagent\t2 put\n",
      "\tagent\t1 displayed\n",
      "\tagent\t1 went\n",
      "\tagent\t1 growing\n",
      "\tagent\t1 come\n",
      "\tagent\t1 insisted\n",
      "\tagent\t1 assured\n",
      "\tagent\t1 consider\n",
      "\tagent\t1 marshal\n",
      "\tagent\t1 deploy\n",
      "\tagent\t1 charge\n",
      "\tagent\t1 had\n",
      "\tagent\t1 wore\n",
      "\tagent\t1 doff\n",
      "\tagent\t1 entered\n",
      "\tagent\t1 appreciate\n",
      "\tagent\t1 abate\n",
      "\tagent\t1 felt\n",
      "\tagent\t1 gobble\n",
      "\tagent\t1 taken\n",
      "\tagent\t1 kick\n",
      "\tagent\t1 dropped\n",
      "\tagent\t1 sat\n",
      "\tagent\t1 step\n",
      "\tagent\t1 black\n",
      "\tagent\t1 rose\n",
      "\tagent\t1 threw\n",
      "\tagent\t1 hurrying\n",
      "\tagent\t1 decide\n",
      "\tagent\t1 changed\n",
      "\tagent\t1 speak\n",
      "\tagent\t1 see\n",
      "\tagent\t1 refer\n",
      "\tagent\t1 kept\n",
      "\tagent\t1 thinking\n",
      "\tagent\t1 got\n",
      "\tagent\t1 withdraw\n",
      "\tagent\t1 prefer\n",
      "\tagent\t1 began\n",
      "\tagent\t1 overturn\n",
      "\n",
      "\tpatient\t1 consider\n",
      "\tpatient\t1 put\n",
      "\tpatient\t1 keep\n",
      "\tpatient\t1 presented\n",
      "\tpatient\t1 calling\n",
      "\tpatient\t1 roared\n",
      "\tpatient\t1 detained\n",
      "\tpatient\t1 rousing\n",
      "\tpatient\t1 regards\n",
      "\tpatient\t1 cried\n",
      "\tpatient\t1 asked\n",
      "\tpatient\t1 crowding\n",
      "\n",
      "\tmod\t1 short\n",
      "\tmod\t1 idle\n",
      "\tmod\t1 averse\n",
      "\tmod\t1 apt\n",
      "\tmod\t1 incautious\n",
      "\tmod\t1 reckless\n",
      "\tmod\t1 person\n",
      "\tmod\t1 worse\n",
      "\tmod\t1 man\n",
      "\n",
      "33 79 Nippers he/him/his\n",
      "\n",
      "\tposs\t2 back\n",
      "\tposs\t2 arms\n",
      "\tposs\t1 chin\n",
      "\tposs\t1 desk:—then\n",
      "\tposs\t1 waistbands\n",
      "\tposs\t1 ambition\n",
      "\tposs\t1 clients\n",
      "\tposs\t1 client\n",
      "\tposs\t1 failings\n",
      "\tposs\t1 compatriot\n",
      "\tposs\t1 faults\n",
      "\tposs\t1 vintner\n",
      "\tposs\t1 birth\n",
      "\tposs\t1 seat\n",
      "\tposs\t1 table\n",
      "\tposs\t1 mood\n",
      "\tposs\t1 chair\n",
      "\tposs\t1 maledictions\n",
      "\tposs\t1 part\n",
      "\n",
      "\tagent\t2 wanted\n",
      "\tagent\t1 worked\n",
      "\tagent\t1 get\n",
      "\tagent\t1 put\n",
      "\tagent\t1 went\n",
      "\tagent\t1 brought\n",
      "\tagent\t1 wrote\n",
      "\tagent\t1 declared\n",
      "\tagent\t1 lowered\n",
      "\tagent\t1 stooped\n",
      "\tagent\t1 knew\n",
      "\tagent\t1 had\n",
      "\tagent\t1 called\n",
      "\tagent\t1 did\n",
      "\tagent\t1 insisted\n",
      "\tagent\t1 chose\n",
      "\tagent\t1 dressed\n",
      "\tagent\t1 reflected\n",
      "\tagent\t1 observed\n",
      "\tagent\t1 rise\n",
      "\tagent\t1 stooping\n",
      "\tagent\t1 spread\n",
      "\tagent\t1 taken\n",
      "\tagent\t1 said\n",
      "\tagent\t1 ’s\n",
      "\tagent\t1 ground\n",
      "\tagent\t1 do\n",
      "\tagent\t1 has\n",
      "\tagent\t1 approached\n",
      "\tagent\t1 withdraw\n",
      "\tagent\t1 caught\n",
      "\tagent\t1 asked\n",
      "\tagent\t1 abated\n",
      "\n",
      "\tpatient\t2 calling\n",
      "\tpatient\t1 suit\n",
      "\tpatient\t1 touching\n",
      "\tpatient\t1 charged\n",
      "\tpatient\t1 vexing\n",
      "\tpatient\t1 kick\n",
      "\tpatient\t1 tell\n",
      "\n",
      "\tmod\t2 man\n",
      "\tmod\t1 considerable\n",
      "\tmod\t1 mild\n",
      "\n",
      "34 32 Ginger Nut he/him/his\n",
      "\n",
      "\tposs\t2 duty\n",
      "\tposs\t1 father\n",
      "\tposs\t1 blending\n",
      "\tposs\t1 mouth\n",
      "\tposs\t1 moistening\n",
      "\tposs\t1 clapping\n",
      "\tposs\t1 lips\n",
      "\tposs\t1 account\n",
      "\n",
      "\tagent\t2 use\n",
      "\tagent\t2 think\n",
      "\tagent\t1 had\n",
      "\tagent\t1 discharged\n",
      "\tagent\t1 mollified\n",
      "\tagent\t1 said\n",
      "\tagent\t1 hear\n",
      "\tagent\t1 vouchsafed\n",
      "\tagent\t1 advance\n",
      "\tagent\t1 munched\n",
      "\tagent\t1 standing\n",
      "\n",
      "\tpatient\t2 sent\n",
      "\tpatient\t1 named\n",
      "\tpatient\t1 dismissing\n",
      "\tpatient\t1 replied\n",
      "\n",
      "\tmod\t1 lad\n",
      "\n",
      "40 4 Colt he/him/his\n",
      "\n",
      "\tposs\t1 act\n",
      "\n",
      "\n",
      "\tpatient\t1 incensed\n",
      "\tpatient\t1 permitting\n",
      "\n",
      "\n",
      "41 4 Edwards he/him/his\n",
      "\n",
      "\n",
      "\tagent\t1 died\n",
      "\n",
      "\tpatient\t1 know\n",
      "\n",
      "\n",
      "47 4 Project Gutenberg they/them/their\n",
      "\n",
      "\n",
      "\n",
      "\tpatient\t1 created\n",
      "\n",
      "\n",
      "31 3 the late John Jacob Astor he/him/his\n",
      "\n",
      "\tposs\t1 opinion\n",
      "\n",
      "\tagent\t1 had\n",
      "\n",
      "\n",
      "\n",
      "28 2 Herman Melville he/him/his\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "36 2 Cicero he/him/his\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "39 2 the unfortunate Adams he/him/his\n",
      "\n",
      "\n",
      "\tagent\t1 incensed\n",
      "\n",
      "\n",
      "\n",
      "44 2 Mr. Cutlets he/him/his\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "45 2 Mrs. Cutlets she/her\n",
      "\n",
      "\tposs\t1 room\n",
      "\n",
      "\tagent\t1 have\n",
      "\n",
      "\n",
      "\n",
      "48 2 Professor Michael S. Hart he/him/his\n",
      "\n",
      "\n",
      "\tagent\t1 produced\n",
      "\n",
      "\n",
      "\tmod\t1 originator\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_counter_from_dependency_list(dep_list):\n",
    "    counter=Counter()\n",
    "    for token in dep_list:\n",
    "        term=token[\"w\"]\n",
    "        tokenGlobalIndex=token[\"i\"]\n",
    "        counter[term]+=1\n",
    "    return counter\n",
    "\n",
    "for character in data[\"characters\"]:\n",
    "\n",
    "    agentList=character[\"agent\"]\n",
    "    patientList=character[\"patient\"]\n",
    "    possList=character[\"poss\"]\n",
    "    modList=character[\"mod\"]\n",
    "\n",
    "    character_id=character[\"id\"]\n",
    "    count=character[\"count\"]\n",
    "\n",
    "    referential_gender_distribution=referential_gender_prediction=\"unknown\"\n",
    "\n",
    "    if character[\"g\"] is not None and character[\"g\"] != \"unknown\":\n",
    "        referential_gender_distribution=character[\"g\"][\"inference\"]\n",
    "        referential_gender=character[\"g\"][\"argmax\"]\n",
    "\n",
    "    mentions=character[\"mentions\"]\n",
    "    proper_mentions=mentions[\"proper\"]\n",
    "    max_proper_mention=\"\"\n",
    "\n",
    "    # just print out information about named characters\n",
    "    if len(mentions[\"proper\"]) > 0:\n",
    "        max_proper_mention=mentions[\"proper\"][0][\"n\"]\n",
    "\n",
    "        print(character_id, count, max_proper_mention, referential_gender)\n",
    "\n",
    "        print()\n",
    "        printTop=100\n",
    "        for k, v in get_counter_from_dependency_list(possList).most_common(printTop):\n",
    "            print(\"\\tposs\\t%s %s\" % (v,k))\n",
    "        print()\n",
    "        for k, v in get_counter_from_dependency_list(agentList).most_common(printTop):\n",
    "            print(\"\\tagent\\t%s %s\" % (v,k))\n",
    "        print()\n",
    "        for k, v in get_counter_from_dependency_list(patientList).most_common(printTop):\n",
    "            print(\"\\tpatient\\t%s %s\" % (v,k))\n",
    "        print()\n",
    "        for k, v in get_counter_from_dependency_list(modList).most_common(printTop):\n",
    "            print(\"\\tmod\\t%s %s\" % (v,k))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_tokens = pd.read_csv(\"./output_dir/bartleby/bartleby.tokens\", delimiter=\"\\t\")\n",
    "df_entities = pd.read_csv(\"./output_dir/bartleby/bartleby.entities\", delimiter=\"\\t\")\n",
    "\n",
    "#create dictionary with the shape [sentence_ID][token_ID_within_sentence][word]\n",
    "sentence_and_token_ID_to_word_dict = {}\n",
    "for character in data[\"characters\"]:\n",
    "    character_id=character[\"id\"]\n",
    "    mentions=character[\"mentions\"]\n",
    "    proper_mentions=mentions[\"proper\"]\n",
    "    if len(mentions[\"proper\"]) > 0:\n",
    "        max_proper_mention=mentions[\"proper\"][0][\"n\"]\n",
    "    else:\n",
    "        max_proper_mention = character_id\n",
    "\n",
    "    unique_start_token_ids = df_entities.loc[df_entities['COREF'] == character_id, 'start_token']\n",
    "    #print(unique_start_token_ids)\n",
    "    sentence_ids = df_tokens[df_tokens['token_ID_within_document'].isin(unique_start_token_ids)][['token_ID_within_document', 'token_ID_within_sentence', 'sentence_ID']]\n",
    "    sentence_ids = sentence_ids.reset_index(drop=True)\n",
    "\n",
    "    for index, row in sentence_ids.iterrows():\n",
    "        sentence_ID = row['sentence_ID']\n",
    "        token_ID = row['token_ID_within_sentence']\n",
    "        combined_sentence_and_token_ID = str(sentence_ID) +\":\"+ str(token_ID)\n",
    "        sentence_and_token_ID_to_word_dict[combined_sentence_and_token_ID] = max_proper_mention\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0           5\n",
      "12        107\n",
      "17        163\n",
      "19        177\n",
      "36        304\n",
      "        ...  \n",
      "2456    17354\n",
      "2458    17363\n",
      "2468    17483\n",
      "2472    17499\n",
      "2483    17670\n",
      "Name: start_token, Length: 522, dtype: int64\n",
      "     token_ID_within_document  token_ID_within_sentence  sentence_ID\n",
      "0                           5                         5            0\n",
      "1                         107                         2            3\n",
      "2                         163                         0            4\n",
      "3                         177                        14            4\n",
      "4                         304                        17            8\n",
      "..                        ...                       ...          ...\n",
      "290                     17354                        35          791\n",
      "291                     17363                        44          791\n",
      "292                     17483                         6          795\n",
      "293                     17499                        22          795\n",
      "294                     17670                         0          803\n",
      "\n",
      "[295 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "character = data[\"characters\"][1]\n",
    "character_id=character[\"id\"]\n",
    "\n",
    "#get all sentencs where COREF = character_id\n",
    "unique_start_token_ids = df_entities.loc[df_entities['COREF'] == character_id, 'start_token']\n",
    "print(unique_start_token_ids)\n",
    "sentence_ids = df_tokens[df_tokens['token_ID_within_document'].isin(unique_start_token_ids)][['token_ID_within_document', 'token_ID_within_sentence', 'sentence_ID']]\n",
    "sentence_ids = sentence_ids.reset_index(drop=True)\n",
    "print(sentence_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from allennlp.predictors.predictor import Predictor\n",
    "SRL_MODEL_PATH = \"srl.tar.gz\"\n",
    "predictor_srl = Predictor.from_path(SRL_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_arg(n, arg_name, dict_name, sentence_ID):\n",
    "    if arg_name in n[\"tags\"]:\n",
    "        index = n['tags'].index(arg_name)\n",
    "        if str(sentence_ID)+\":\"+str(index) in dict_name.keys():\n",
    "            return dict_name[str(sentence_ID)+\":\"+str(index)]\n",
    "        else:\n",
    "            return None\n",
    "    else:\n",
    "        return None\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['sentence_ID', 'verb', 'agent', 'patient']\n",
    "srl_results_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "# for each mention in our coreference cluster do the following\n",
    "for index, row in sentence_ids.iterrows():\n",
    "    token_ID_within_document = row['token_ID_within_document']\n",
    "    #word = df_tokens.loc[df_tokens['token_ID_within_document'] == token_ID_within_document, 'word'].values[0]\n",
    "\n",
    "    sentence_ID = df_tokens.loc[df_tokens['token_ID_within_document'] == token_ID_within_document, 'sentence_ID'].values[0]\n",
    "    words_list = df_tokens.loc[df_tokens['sentence_ID'] == sentence_ID, 'word'].tolist()\n",
    "    token_ID_within_sentence = row['token_ID_within_sentence']\n",
    "    sentence_for_srl = ' '.join(words_list)\n",
    "    predictions_srl = predictor_srl.predict(sentence_for_srl)\n",
    "\n",
    "    for n in predictions_srl['verbs']:\n",
    "        if token_ID_within_sentence < len(n['tags']):\n",
    "            tag = n['tags'][token_ID_within_sentence]\n",
    "            if \"B-ARG0\" in tag:\n",
    "\n",
    "                word = check_for_arg(n, \"B-ARG1\", sentence_and_token_ID_to_word_dict, sentence_ID)\n",
    "                if word != None:\n",
    "                    new_row = pd.DataFrame({'sentence_ID': [sentence_ID], 'verb': [utils.lemmatize(n['verb'], nlp)], 'agent': [\"protag\"], 'patient': [word]})\n",
    "                    srl_results_df = pd.concat([srl_results_df, new_row], ignore_index=True)\n",
    "            elif \"B-ARG1\" in tag:\n",
    "                word = check_for_arg(n, \"B-ARG0\", sentence_and_token_ID_to_word_dict, sentence_ID)\n",
    "                if word != None:\n",
    "                    new_row = pd.DataFrame({'sentence_ID': [sentence_ID], 'verb': [utils.lemmatize(n['verb'], nlp)], 'agent': [word], 'patient': [\"protag\"]})\n",
    "                    srl_results_df = pd.concat([srl_results_df, new_row], ignore_index=True)\n",
    "\n",
    "srl_results_df.to_csv('srl_output_bartleby.csv', index=False)\n",
    "del srl_results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
